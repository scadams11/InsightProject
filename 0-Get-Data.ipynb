{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "\n",
    "import datetime\n",
    "import dateparser\n",
    "\n",
    "import hydrofunctions as hf\n",
    "\n",
    "import fbprophet \n",
    "from fbprophet.diagnostics import cross_validation\n",
    "\n",
    "# For inputting City information to get distance to sensors.\n",
    "from  geopy.geocoders import Nominatim\n",
    "import geopy.distance\n",
    "\n",
    "# Date time conversion registration.\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading in site data from 'Gage_sites.txt'\n",
    "file = 'Gage_sites.txt'\n",
    "sites = pd.read_csv(file, sep = '\\t', header = 39, skiprows = [40], dtype = {\"site_no\" : \"str\"})\n",
    "\n",
    "##Removing sites without data\n",
    "#x_too_old = sites.drop([65, 71, 77, 117, 118, 138, 203, 225, \n",
    "#                        320, 330, 331, 338]\n",
    "#                       , inplace = True) \n",
    "sites.drop([65, 71, 77, 117, 118, 138, 203, 225, 320, 330, 331, 338], inplace = True)\n",
    "\n",
    "#x_too_new = sites.drop([18, 83, 84, 85, 89, 92, 101, 103, 104, \n",
    "#                        136, 138, 146, 148, 149, 150, 151, 179,\n",
    "#                        208, 209, 224, 228, 231, 236, 293]\n",
    "#                       , inplace = True)\n",
    "\n",
    "site_no = list(sites[\"site_no\"])\n",
    "site_nm = list(sites[\"station_nm\"])\n",
    "site_loc = sites.filter(['site_no', 'station_nm', 'dec_lat_va', 'dec_long_va'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = 'usgs_stream_db'\n",
    "username = 'cadeadams'\n",
    "\n",
    "engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n",
    "\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[230.41453120574732, 299.12043536370714, 423.05635695726676]\n",
      "[174.5370202258796, 253.48735318298114, 309.8214353732134]\n",
      "[129.77860381352696, 205.5372636417656, 154.6292389192572]\n"
     ]
    }
   ],
   "source": [
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username)\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT * FROM site_locations;\n",
    "\"\"\"\n",
    "\n",
    "query_results = pd.read_sql_query(sql_query,con)\n",
    "\n",
    "location = [38.7511041, -105.521384]\n",
    "date = \"Sep 23, 2020\"\n",
    "t = dateparser.parse(date)\n",
    "\n",
    "site_no = query_results[\"site_no\"]\n",
    "site_lat = query_results[\"dec_lat_va\"]\n",
    "site_long = query_results[\"dec_long_va\"]\n",
    "\n",
    "sites_coord = pd.DataFrame([site_no, site_lat, site_long])\n",
    "sites_coord = sites_coord.T\n",
    "\n",
    "distance = []\n",
    "for i in range(len(sites_coord)) :\n",
    "    distance.append(geopy.distance.distance(location, sites_coord.iloc[i,1:]).miles)\n",
    "\n",
    "query_results[\"distance\"] = distance\n",
    "site_no = pd.DataFrame(site_no)\n",
    "site_no[\"distance\"] = distance\n",
    "query_results = query_results.sort_values(by = [\"distance\"])\n",
    "site_no = site_no.sort_values(by = [\"distance\"])\n",
    "\n",
    "count = 0\n",
    "loc_lat = list()\n",
    "loc_lon = list()\n",
    "flow = list()\n",
    "flow_upper = list()\n",
    "flow_lower = list()\n",
    "good_site = list()\n",
    "good_dist = list()\n",
    "\n",
    "for i in range(len(site_no)) :\n",
    "    sql_query_model = \"\"\"\n",
    "                      SELECT * FROM n\"\"\"+site_no['site_no'].iloc[i]+\"\"\"_forecast;\n",
    "                      \"\"\"\n",
    "    query_results_model = pd.read_sql_query(sql_query_model,con)\n",
    "    if (t == query_results_model['ds']).any() :\n",
    "        temp = query_results_model.loc[query_results_model['ds'] == t]\n",
    "        if (temp['yhat'].iloc[0] > 100 and temp['yhat'].iloc[0] < 400) :\n",
    "            loc_lat.append(float(query_results[i:i+1][\"dec_lat_va\"]))\n",
    "            loc_lon.append(float(query_results[i:i+1][\"dec_long_va\"]))\n",
    "            good_site.append(query_results[i:i+1][\"site_no\"].iloc[0])\n",
    "            good_dist.append(query_results[i:i+1][\"distance\"].iloc[0])\n",
    "            flow.append(temp['yhat'].iloc[0])\n",
    "            flow_upper.append(temp['yhat_upper'].iloc[0])\n",
    "            flow_lower.append(temp['yhat_lower'].iloc[0])\n",
    "            count = count + 1\n",
    "            if count == 3 :\n",
    "                break\n",
    "        else :\n",
    "            continue\n",
    "\n",
    "print(flow_upper)\n",
    "print(flow)\n",
    "print(flow_lower)\n",
    "#loc1_lat = float(query_results[0:1][\"dec_lat_va\"])\n",
    "#loc1_lon = float(query_results[0:1][\"dec_long_va\"])\n",
    "#location_1 = pd.DataFrame([loc1_lat, loc1_lon])\n",
    "#print(query_results.head())\n",
    "#print(site_no.head())\n",
    "\n",
    "#site_data_from_sql = pd.read_sql_query(sql_query_dat,con)\n",
    "#site_model_from_sql = pd.read_sql_query(sql_query_mod,con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Making 26 forecasts with cutoffs between 2006-10-02 00:00:00 and 2019-01-27 00:00:00\n",
      "/Users/cadeadams/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in true_divide\n",
      "\n",
      "INFO:fbprophet:Making 3 forecasts with cutoffs between 2018-01-31 00:00:00 and 2019-01-26 00:00:00\n",
      "INFO:fbprophet:Making 33 forecasts with cutoffs between 2003-04-20 00:00:00 and 2019-01-26 00:00:00\n",
      "INFO:fbprophet:Making 28 forecasts with cutoffs between 2005-10-06 00:00:00 and 2019-01-26 00:00:00\n",
      "INFO:fbprophet:Making 33 forecasts with cutoffs between 2003-04-20 00:00:00 and 2019-01-26 00:00:00\n",
      "INFO:fbprophet:Making 19 forecasts with cutoffs between 2010-01-18 00:00:00 and 2018-12-02 00:00:00\n",
      "INFO:fbprophet:Making 33 forecasts with cutoffs between 2003-04-20 00:00:00 and 2019-01-26 00:00:00\n",
      "INFO:fbprophet:Making 20 forecasts with cutoffs between 2009-07-24 00:00:00 and 2018-12-04 00:00:00\n",
      "INFO:fbprophet:Making 8 forecasts with cutoffs between 2015-05-20 00:00:00 and 2018-10-31 00:00:00\n",
      "INFO:fbprophet:Making 33 forecasts with cutoffs between 2003-04-20 00:00:00 and 2019-01-26 00:00:00\n",
      "INFO:fbprophet:Making 33 forecasts with cutoffs between 2003-04-07 00:00:00 and 2019-01-13 00:00:00\n",
      "INFO:fbprophet:Making 30 forecasts with cutoffs between 2004-08-10 00:00:00 and 2018-11-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "mape_baseline = list()\n",
    "for site in site_no[315:] :\n",
    "    sql_query = \"\"\"\n",
    "                SELECT * FROM n\"\"\"+site+\"\"\";\n",
    "                \"\"\"\n",
    "    site_data_from_sql = pd.read_sql_query(sql_query,con)\n",
    "\n",
    "    df_prophet = fbprophet.Prophet(changepoint_prior_scale=0.05, daily_seasonality=True, interval_width = 0.25)\n",
    "    df_prophet.fit(site_data_from_sql)\n",
    "\n",
    "    cv_results = cross_validation(df_prophet, initial = '1095 days', period = '180 days', horizon = '365 days')\n",
    "    cv_results.to_sql(\"n\"+str(site)+\"_cv\", engine, if_exists='replace')\n",
    "    mape_baseline.append(mean_absolute_percentage_error(cv_results.y, cv_results.yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cadeadams/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in true_divide\n",
      "\n",
      "/Users/cadeadams/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in true_divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    site_no  mape_baseline  elevation\n",
      "0  06614800     191.438191   10390.00\n",
      "1  06620000     180.378014    7810.39\n",
      "2  06696980     114.760852    9935.00\n",
      "3  06700000      70.095801    6845.86\n",
      "4  06701620     236.782235    7440.00\n"
     ]
    }
   ],
   "source": [
    "cross_val_all = pd.DataFrame()\n",
    "\n",
    "file = 'Gage_sites.txt'\n",
    "\n",
    "sites_cv = pd.read_csv(file, sep = '\\t', header = 39, skiprows = [40], dtype = {\"site_no\" : \"str\"})\n",
    "\n",
    "##Removes sites with no data for past 20 years.\n",
    "sites_cv = sites_cv.drop([65, 71, 77, 117, 118, 138, 203, 225, 320, 330, 331, 338])\n",
    "sites_cv = sites_cv.reset_index(drop = True)\n",
    "\n",
    "##Removes data that is unable to be cross validated due to too few observations.\n",
    "sites_cv = sites_cv.drop([18, 83, 84, 85, 89, 92, 101, 103, 104, 136, 138, 146, 148, 149, 150, 151, 179, 208, 209, 224, 228, 231, 236, 293, 314])\n",
    "sites_cv = sites_cv.reset_index(drop = True)\n",
    "\n",
    "site_no_cv = list(sites_cv[\"site_no\"])\n",
    "site_nm_cv = list(sites_cv[\"station_nm\"])\n",
    "site_ele_cv = list(sites_cv[\"alt_va\"])\n",
    "\n",
    "cross_val_all[\"site_no\"] = site_no_cv\n",
    "\n",
    "mape_baseline = list()\n",
    "for site in site_no_cv :\n",
    "    sql_query = \"\"\"\n",
    "                SELECT * FROM n\"\"\"+site+\"\"\"_cv;\n",
    "                \"\"\"\n",
    "    site_cv_from_sql = pd.read_sql_query(sql_query,con)\n",
    "    mape_baseline.append(mean_absolute_percentage_error(site_cv_from_sql.y, site_cv_from_sql.yhat))\n",
    "\n",
    "cross_val_all[\"mape_baseline\"] = mape_baseline\n",
    "cross_val_all[\"elevation\"] = site_ele_cv\n",
    "print(cross_val_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(cross_val_all[\"elevation\"], cross_val_all[\"mape_baseline\"])\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.savefig(\"cv_eda.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     245.000000\n",
      "mean      264.221824\n",
      "std       367.922762\n",
      "min        37.889536\n",
      "25%       104.716382\n",
      "50%       163.797031\n",
      "75%       265.845234\n",
      "max      4015.169617\n",
      "Name: mape_baseline, dtype: float64\n",
      "site_no           0\n",
      "mape_baseline    57\n",
      "elevation         1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cross_val_nona = cross_val_all.replace([np.inf, -np.inf], np.nan)\n",
    "print(cross_val_nona[\"mape_baseline\"].describe())\n",
    "print(cross_val_nona.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-72301ced60c0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-72301ced60c0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    n06711040 (207 days only) 18\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "n06711040 (207 days only) 18\n",
    "n07103784 (257 days only) 83\n",
    "n07103791 (257 days only) 84\n",
    "n07103792 (471 days only) 85\n",
    "n07103965 (676 days only) 89\n",
    "n07103987 (646 days only) 92\n",
    "n07105780 (814 days only) 101\n",
    "n07105815 (868 days only) 103\n",
    "n07105820 (867 days only) 104\n",
    "n09019000 (405 days only) 136\n",
    "n09021000 (677 days only) 138\n",
    "n09032050 (288 days only) 146\n",
    "n09032200 (295 days only) 148\n",
    "n09032300 (304 days only) 149\n",
    "n09032990 (337 days only) 150\n",
    "n09033010 (309 days only) 151\n",
    "n09060799 (867 days only) 179\n",
    "n09076000 (757 days only) 208\n",
    "n09076300 (575 days only) 209\n",
    "n09110990 (447 days only) 224\n",
    "n09113500 (245 days only) 228\n",
    "n09114520 (459 days only) 231\n",
    "n09124010 (188 days only) 236\n",
    "n09352800 (647 days only) 293\n",
    "n383103106594200 (803 days only) 314\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_no.index('06711040')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast = df_prophet.make_future_dataframe(periods=365 * 1, freq='D')\n",
    "df_forecast = df_prophet.predict(df_forecast)\n",
    "df_prophet.plot(df_forecast)\n",
    "plt.xlabel('Date')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Discharge (cfs)')\n",
    "plt.savefig('test.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>trend</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "      <th>trend_lower</th>\n",
       "      <th>trend_upper</th>\n",
       "      <th>additive_terms</th>\n",
       "      <th>additive_terms_lower</th>\n",
       "      <th>additive_terms_upper</th>\n",
       "      <th>weekly</th>\n",
       "      <th>weekly_lower</th>\n",
       "      <th>weekly_upper</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yearly_lower</th>\n",
       "      <th>yearly_upper</th>\n",
       "      <th>multiplicative_terms</th>\n",
       "      <th>multiplicative_terms_lower</th>\n",
       "      <th>multiplicative_terms_upper</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3513</th>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>-932.269063</td>\n",
       "      <td>173.453690</td>\n",
       "      <td>236.958924</td>\n",
       "      <td>-932.269063</td>\n",
       "      <td>-932.269063</td>\n",
       "      <td>1133.681856</td>\n",
       "      <td>1133.681856</td>\n",
       "      <td>1133.681856</td>\n",
       "      <td>0.390274</td>\n",
       "      <td>0.390274</td>\n",
       "      <td>0.390274</td>\n",
       "      <td>1133.291582</td>\n",
       "      <td>1133.291582</td>\n",
       "      <td>1133.291582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201.412793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3514</th>\n",
       "      <td>2020-09-26</td>\n",
       "      <td>-932.165895</td>\n",
       "      <td>168.918588</td>\n",
       "      <td>231.281007</td>\n",
       "      <td>-932.165895</td>\n",
       "      <td>-932.165895</td>\n",
       "      <td>1133.189392</td>\n",
       "      <td>1133.189392</td>\n",
       "      <td>1133.189392</td>\n",
       "      <td>-0.603464</td>\n",
       "      <td>-0.603464</td>\n",
       "      <td>-0.603464</td>\n",
       "      <td>1133.792857</td>\n",
       "      <td>1133.792857</td>\n",
       "      <td>1133.792857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201.023497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3515</th>\n",
       "      <td>2020-09-27</td>\n",
       "      <td>-932.062727</td>\n",
       "      <td>155.987371</td>\n",
       "      <td>229.940654</td>\n",
       "      <td>-932.062727</td>\n",
       "      <td>-932.062727</td>\n",
       "      <td>1133.518593</td>\n",
       "      <td>1133.518593</td>\n",
       "      <td>1133.518593</td>\n",
       "      <td>-1.308300</td>\n",
       "      <td>-1.308300</td>\n",
       "      <td>-1.308300</td>\n",
       "      <td>1134.826893</td>\n",
       "      <td>1134.826893</td>\n",
       "      <td>1134.826893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201.455867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516</th>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>-931.959559</td>\n",
       "      <td>163.611683</td>\n",
       "      <td>240.809111</td>\n",
       "      <td>-931.959559</td>\n",
       "      <td>-931.959559</td>\n",
       "      <td>1136.049050</td>\n",
       "      <td>1136.049050</td>\n",
       "      <td>1136.049050</td>\n",
       "      <td>-0.191631</td>\n",
       "      <td>-0.191631</td>\n",
       "      <td>-0.191631</td>\n",
       "      <td>1136.240681</td>\n",
       "      <td>1136.240681</td>\n",
       "      <td>1136.240681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.089492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>-931.856391</td>\n",
       "      <td>174.700698</td>\n",
       "      <td>245.140438</td>\n",
       "      <td>-931.856391</td>\n",
       "      <td>-931.856391</td>\n",
       "      <td>1138.132011</td>\n",
       "      <td>1138.132011</td>\n",
       "      <td>1138.132011</td>\n",
       "      <td>0.356313</td>\n",
       "      <td>0.356313</td>\n",
       "      <td>0.356313</td>\n",
       "      <td>1137.775698</td>\n",
       "      <td>1137.775698</td>\n",
       "      <td>1137.775698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>206.275620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ds       trend  yhat_lower  yhat_upper  trend_lower  trend_upper  \\\n",
       "3513 2020-09-25 -932.269063  173.453690  236.958924  -932.269063  -932.269063   \n",
       "3514 2020-09-26 -932.165895  168.918588  231.281007  -932.165895  -932.165895   \n",
       "3515 2020-09-27 -932.062727  155.987371  229.940654  -932.062727  -932.062727   \n",
       "3516 2020-09-28 -931.959559  163.611683  240.809111  -931.959559  -931.959559   \n",
       "3517 2020-09-29 -931.856391  174.700698  245.140438  -931.856391  -931.856391   \n",
       "\n",
       "      additive_terms  additive_terms_lower  additive_terms_upper    weekly  \\\n",
       "3513     1133.681856           1133.681856           1133.681856  0.390274   \n",
       "3514     1133.189392           1133.189392           1133.189392 -0.603464   \n",
       "3515     1133.518593           1133.518593           1133.518593 -1.308300   \n",
       "3516     1136.049050           1136.049050           1136.049050 -0.191631   \n",
       "3517     1138.132011           1138.132011           1138.132011  0.356313   \n",
       "\n",
       "      weekly_lower  weekly_upper       yearly  yearly_lower  yearly_upper  \\\n",
       "3513      0.390274      0.390274  1133.291582   1133.291582   1133.291582   \n",
       "3514     -0.603464     -0.603464  1133.792857   1133.792857   1133.792857   \n",
       "3515     -1.308300     -1.308300  1134.826893   1134.826893   1134.826893   \n",
       "3516     -0.191631     -0.191631  1136.240681   1136.240681   1136.240681   \n",
       "3517      0.356313      0.356313  1137.775698   1137.775698   1137.775698   \n",
       "\n",
       "      multiplicative_terms  multiplicative_terms_lower  \\\n",
       "3513                   0.0                         0.0   \n",
       "3514                   0.0                         0.0   \n",
       "3515                   0.0                         0.0   \n",
       "3516                   0.0                         0.0   \n",
       "3517                   0.0                         0.0   \n",
       "\n",
       "      multiplicative_terms_upper        yhat  \n",
       "3513                         0.0  201.412793  \n",
       "3514                         0.0  201.023497  \n",
       "3515                         0.0  201.455867  \n",
       "3516                         0.0  204.089492  \n",
       "3517                         0.0  206.275620  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forecast.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ds      trend  yhat_lower  yhat_upper  trend_lower  trend_upper  \\\n",
      "7571 2020-09-23  80.014778   47.740213  108.163608    80.014778    80.014778   \n",
      "\n",
      "      additive_terms  additive_terms_lower  additive_terms_upper     daily  \\\n",
      "7571        9.691244              9.691244              9.691244 -5.712846   \n",
      "\n",
      "      ...    weekly  weekly_lower  weekly_upper     yearly  yearly_lower  \\\n",
      "7571  ... -5.572282     -5.572282     -5.572282  20.976372     20.976372   \n",
      "\n",
      "      yearly_upper  multiplicative_terms  multiplicative_terms_lower  \\\n",
      "7571     20.976372                   0.0                         0.0   \n",
      "\n",
      "      multiplicative_terms_upper       yhat  \n",
      "7571                         0.0  89.706022  \n",
      "\n",
      "[1 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "#type(pd.to_datetime(site_model_from_sql['ds']))\n",
    "date = \"Sep 23, 2020\"\n",
    "t = dateparser.parse(date)\n",
    "df_forecast.loc[df_forecast['ds'] == t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything below here is for collection and placing into PostgreSQL database. FBProphet models are also performed over all data collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site_no.index('394220106431500') ## Has water temp data. Need to extract...\n",
    "\n",
    "site_loc.to_sql('site_locations', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Pulling in data using hydrofunctions and saving to PostgreSQL database.\n",
    "##\n",
    "start = '2000-01-01'\n",
    "end = str(datetime.datetime.today().strftime('%Y-%m-%d')) #Gets today's date.\n",
    "\n",
    "for site in site_no :\n",
    "    herring = hf.NWIS(site, 'dv', start, end)\n",
    "    herring.get_data()\n",
    "    my_dict = herring.json()\n",
    "    df = hf.extract_nwis_df(my_dict)\n",
    "    df.rename(index=str, columns = {\"USGS:\"+site+\":00060:00003\" : \"y\", \n",
    "                                    \"USGS:\"+site+\":00060:00003_qualifiers\" : \"flags\"}, \n",
    "             inplace = True)\n",
    "    df['ds'] = df.index[:]\n",
    "#    df['ds'].str.split(pat = ' ', expand = True)\n",
    "    df.to_sql(\"n\"+str(site), engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Modeling data using fbprophet and saving to PostgreSQL database.\n",
    "##\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username)\n",
    "\n",
    "for site in site_no :\n",
    "    sql_query = \"\"\"\n",
    "    SELECT * FROM n\"\"\"+site+\"\"\";\n",
    "    \"\"\"\n",
    "    site_data_from_sql = pd.read_sql_query(sql_query,con)\n",
    "    df_prophet = fbprophet.Prophet(changepoint_prior_scale=0.05, daily_seasonality=True, interval_width = 0.25)\n",
    "    df_prophet.fit(site_data_from_sql)\n",
    "    df_forecast = df_prophet.make_future_dataframe(periods=365 * 1, freq='D')\n",
    "    df_forecast = df_prophet.predict(df_forecast)\n",
    "    df_forecast.to_sql(\"n\"+str(site)+\"_forecast\", engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()\n",
    "plt.xlabel('Date')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Discharge (cfs)')\n",
    "plt.title('Daily Mean Discharge for Roaring Fork River')\n",
    "plt.savefig('RRFork1.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fbprophet.forecaster.Prophet at 0x115c026a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prophet = fbprophet.Prophet(changepoint_prior_scale=0.05, daily_seasonality=True, interval_width = 0.25)\n",
    "df_prophet.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast = df_prophet.make_future_dataframe(periods=365 * 1, freq='D')\n",
    "df_forecast = df_prophet.predict(df_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prophet.plot_components(df_forecast)\n",
    "plt.savefig('RRFork1_Components.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ds</th>\n",
       "      <th>trend</th>\n",
       "      <th>yhat_lower</th>\n",
       "      <th>yhat_upper</th>\n",
       "      <th>trend_lower</th>\n",
       "      <th>trend_upper</th>\n",
       "      <th>additive_terms</th>\n",
       "      <th>additive_terms_lower</th>\n",
       "      <th>additive_terms_upper</th>\n",
       "      <th>...</th>\n",
       "      <th>weekly</th>\n",
       "      <th>weekly_lower</th>\n",
       "      <th>weekly_upper</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yearly_lower</th>\n",
       "      <th>yearly_upper</th>\n",
       "      <th>multiplicative_terms</th>\n",
       "      <th>multiplicative_terms_lower</th>\n",
       "      <th>multiplicative_terms_upper</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7691</th>\n",
       "      <td>7691</td>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>0.967861</td>\n",
       "      <td>-0.579543</td>\n",
       "      <td>1.447869</td>\n",
       "      <td>0.967861</td>\n",
       "      <td>0.967861</td>\n",
       "      <td>-0.477573</td>\n",
       "      <td>-0.477573</td>\n",
       "      <td>-0.477573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020013</td>\n",
       "      <td>0.020013</td>\n",
       "      <td>0.020013</td>\n",
       "      <td>-2.623681</td>\n",
       "      <td>-2.623681</td>\n",
       "      <td>-2.623681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.490288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7692</th>\n",
       "      <td>7692</td>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>0.968049</td>\n",
       "      <td>-0.603034</td>\n",
       "      <td>1.530899</td>\n",
       "      <td>0.968049</td>\n",
       "      <td>0.968049</td>\n",
       "      <td>-0.491970</td>\n",
       "      <td>-0.491970</td>\n",
       "      <td>-0.491970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016397</td>\n",
       "      <td>0.016397</td>\n",
       "      <td>0.016397</td>\n",
       "      <td>-2.634462</td>\n",
       "      <td>-2.634462</td>\n",
       "      <td>-2.634462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7693</th>\n",
       "      <td>7693</td>\n",
       "      <td>2021-01-23</td>\n",
       "      <td>0.968238</td>\n",
       "      <td>-0.522904</td>\n",
       "      <td>1.572616</td>\n",
       "      <td>0.968238</td>\n",
       "      <td>0.968238</td>\n",
       "      <td>-0.525330</td>\n",
       "      <td>-0.525330</td>\n",
       "      <td>-0.525330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008017</td>\n",
       "      <td>-0.008017</td>\n",
       "      <td>-0.008017</td>\n",
       "      <td>-2.643407</td>\n",
       "      <td>-2.643407</td>\n",
       "      <td>-2.643407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.442908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>7694</td>\n",
       "      <td>2021-01-24</td>\n",
       "      <td>0.968426</td>\n",
       "      <td>-0.578047</td>\n",
       "      <td>1.476846</td>\n",
       "      <td>0.968426</td>\n",
       "      <td>0.968426</td>\n",
       "      <td>-0.533844</td>\n",
       "      <td>-0.533844</td>\n",
       "      <td>-0.533844</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009711</td>\n",
       "      <td>-0.009711</td>\n",
       "      <td>-0.009711</td>\n",
       "      <td>-2.650228</td>\n",
       "      <td>-2.650228</td>\n",
       "      <td>-2.650228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>7695</td>\n",
       "      <td>2021-01-25</td>\n",
       "      <td>0.968615</td>\n",
       "      <td>-0.388971</td>\n",
       "      <td>1.673874</td>\n",
       "      <td>0.968615</td>\n",
       "      <td>0.968615</td>\n",
       "      <td>-0.530558</td>\n",
       "      <td>-0.530558</td>\n",
       "      <td>-0.530558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>-2.654699</td>\n",
       "      <td>-2.654699</td>\n",
       "      <td>-2.654699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index         ds     trend  yhat_lower  yhat_upper  trend_lower  \\\n",
       "7691   7691 2021-01-21  0.967861   -0.579543    1.447869     0.967861   \n",
       "7692   7692 2021-01-22  0.968049   -0.603034    1.530899     0.968049   \n",
       "7693   7693 2021-01-23  0.968238   -0.522904    1.572616     0.968238   \n",
       "7694   7694 2021-01-24  0.968426   -0.578047    1.476846     0.968426   \n",
       "7695   7695 2021-01-25  0.968615   -0.388971    1.673874     0.968615   \n",
       "\n",
       "      trend_upper  additive_terms  additive_terms_lower  additive_terms_upper  \\\n",
       "7691     0.967861       -0.477573             -0.477573             -0.477573   \n",
       "7692     0.968049       -0.491970             -0.491970             -0.491970   \n",
       "7693     0.968238       -0.525330             -0.525330             -0.525330   \n",
       "7694     0.968426       -0.533844             -0.533844             -0.533844   \n",
       "7695     0.968615       -0.530558             -0.530558             -0.530558   \n",
       "\n",
       "      ...    weekly  weekly_lower  weekly_upper    yearly  yearly_lower  \\\n",
       "7691  ...  0.020013      0.020013      0.020013 -2.623681     -2.623681   \n",
       "7692  ...  0.016397      0.016397      0.016397 -2.634462     -2.634462   \n",
       "7693  ... -0.008017     -0.008017     -0.008017 -2.643407     -2.643407   \n",
       "7694  ... -0.009711     -0.009711     -0.009711 -2.650228     -2.650228   \n",
       "7695  ... -0.001953     -0.001953     -0.001953 -2.654699     -2.654699   \n",
       "\n",
       "      yearly_upper  multiplicative_terms  multiplicative_terms_lower  \\\n",
       "7691     -2.623681                   0.0                         0.0   \n",
       "7692     -2.634462                   0.0                         0.0   \n",
       "7693     -2.643407                   0.0                         0.0   \n",
       "7694     -2.650228                   0.0                         0.0   \n",
       "7695     -2.654699                   0.0                         0.0   \n",
       "\n",
       "      multiplicative_terms_upper      yhat  \n",
       "7691                         0.0  0.490288  \n",
       "7692                         0.0  0.476079  \n",
       "7693                         0.0  0.442908  \n",
       "7694                         0.0  0.434582  \n",
       "7695                         0.0  0.438057  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_model_from_sql.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
